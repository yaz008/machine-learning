{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable, Sequence, Iterator, Iterable\n",
    "from dataclasses import dataclass\n",
    "from typing import NamedTuple, Self, cast\n",
    "from pathlib import Path\n",
    "from struct import unpack\n",
    "from itertools import product, chain, islice\n",
    "from math import log10, exp, sqrt\n",
    "from random import random, shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixDim(NamedTuple):\n",
    "    m: int\n",
    "    n: int\n",
    "\n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        return self.m * self.n\n",
    "\n",
    "    @property\n",
    "    def T(self) -> 'MatrixDim':\n",
    "        return MatrixDim(m=self.n, n=self.m)\n",
    "\n",
    "    @property\n",
    "    def is_vector(self) -> bool:\n",
    "        return self.m == 1 or self.n == 1\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f'{self.m} by {self.n}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(slots=True)\n",
    "class Matrix[Numeric: (bool, int, float)]:\n",
    "    __values: tuple[Numeric, ...]\n",
    "    __dim: MatrixDim\n",
    "    __is_transposed: bool\n",
    "    __render_decimals: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        __values: tuple[Numeric, ...],\n",
    "        /,\n",
    "        dim: MatrixDim,\n",
    "        *,\n",
    "        transposed: bool = False,\n",
    "        render_decimals: int = 0,\n",
    "    ) -> None:\n",
    "        self.__values = __values\n",
    "        self.__dim = dim\n",
    "        self.__is_transposed = transposed\n",
    "        self.__render_decimals = render_decimals\n",
    "        if len(__values) != dim.size:\n",
    "            raise ValueError(\n",
    "                f'Cannot interpret {len(__values)} values as {self.dim} matrix'\n",
    "            )\n",
    "    \n",
    "    @property\n",
    "    def dim(self) -> MatrixDim:\n",
    "        return self.__dim if not self.__is_transposed else self.__dim.T\n",
    "\n",
    "    @property\n",
    "    def T(self) -> 'Matrix[Numeric]':\n",
    "        return Matrix(\n",
    "            self.__values,\n",
    "            dim=self.__dim,\n",
    "            transposed=(not self.__is_transposed),\n",
    "            render_decimals=self.__render_decimals,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def as_vector(self) -> Iterator[Numeric]:\n",
    "        if not self.dim.is_vector:\n",
    "            raise ValueError(f'{self.dim} matrix is not a vector')\n",
    "        return iter(self.__values)\n",
    "\n",
    "    def apply(self, __func: Callable[[Numeric], Numeric]) -> 'Matrix[Numeric]':\n",
    "        return Matrix(\n",
    "            tuple(map(__func, self.__values)),\n",
    "            dim=self.dim,\n",
    "            transposed=False,\n",
    "            render_decimals=self.__render_decimals,\n",
    "        )\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        fmt: str = f'{(\n",
    "            int(log10(max(map(abs, self.__values)) or 1))\n",
    "        )}>.{self.__render_decimals}f'\n",
    "        return f'[{'\\n'.join(\n",
    "            f'{' ' * (i != 0)}[{' '.join(\n",
    "                f'{' ' * int(self[i, j] >= 0)}{self[i, j]:{fmt}}'\n",
    "                for j in range(self.dim.n)\n",
    "            )}]'\n",
    "            for i in range(self.dim.m)\n",
    "        )}]'\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        match self.dim:\n",
    "            case (1, l) | (l, 1):\n",
    "                return l\n",
    "        raise ValueError(f'{self.dim} matrix has no length, use matrix.dim instead')\n",
    "\n",
    "    def __getitem__(self, index: tuple[int, int], /) -> Numeric:\n",
    "        return self.__values[(\n",
    "            index[self.__is_transposed] * (\n",
    "                self.dim.m if self.__is_transposed else self.dim.n\n",
    "            ) + index[1 - self.__is_transposed]\n",
    "        )]\n",
    "\n",
    "    def __add__(self, __other: 'Matrix[Numeric]', /) -> 'Matrix[Numeric]':\n",
    "        if self.dim != __other.dim:\n",
    "            raise ValueError(f'Cannot add {self.dim} and {__other.dim} matrices')\n",
    "        return Matrix(\n",
    "            tuple(\n",
    "                self[i, j] + __other[i, j] for i, j\n",
    "                in product(range(self.dim.m), range(self.dim.n))\n",
    "            ),\n",
    "            dim=self.dim,\n",
    "            transposed=False,\n",
    "            render_decimals=max(self.__render_decimals, __other.__render_decimals),\n",
    "        )\n",
    "\n",
    "    def __iadd__(self, __other: 'Matrix[Numeric]') -> Self:\n",
    "        if self.dim != __other.dim:\n",
    "            raise ValueError(f'Cannot add {self.dim} and {__other.dim} matrices')\n",
    "        self.__values = cast(\n",
    "            tuple[Numeric, ...],\n",
    "            tuple(\n",
    "                self[i, j] + __other[i, j] for i, j\n",
    "                in product(range(self.dim.m), range(self.dim.n))\n",
    "            ),\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def __sub__(self, __other: 'Matrix[Numeric]', /) -> 'Matrix[Numeric]':\n",
    "        if self.dim != __other.dim:\n",
    "            raise ValueError(f'Cannot subtract {self.dim} and {__other.dim} matrices')\n",
    "        return Matrix(\n",
    "            tuple(\n",
    "                self[i, j] - __other[i, j] for i, j\n",
    "                in product(range(self.dim.m), range(self.dim.n))\n",
    "            ),\n",
    "            dim=self.dim,\n",
    "            transposed=False,\n",
    "            render_decimals=max(self.__render_decimals, __other.__render_decimals),\n",
    "        )\n",
    "\n",
    "    def __isub__(self, __other: 'Matrix[Numeric]') -> Self:\n",
    "        if self.dim != __other.dim:\n",
    "            raise ValueError(f'Cannot subtract {self.dim} and {__other.dim} matrices')\n",
    "        self.__values = cast(\n",
    "            tuple[Numeric, ...],\n",
    "            tuple(\n",
    "                self[i, j] - __other[i, j] for i, j\n",
    "                in product(range(self.dim.m), range(self.dim.n))\n",
    "            ),\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def __mul__(self, __other: 'Matrix[Numeric]', /) -> 'Matrix[Numeric]':\n",
    "        if self.dim != __other.dim:\n",
    "            raise ValueError(\n",
    "                f'Hadamard requires equal dims, got {self.dim} and {__other.dim}'\n",
    "            )\n",
    "        return Matrix(\n",
    "            tuple(\n",
    "                self[i, j] * __other[i, j] for i, j\n",
    "                in product(range(self.dim.m), range(self.dim.n))\n",
    "            ),\n",
    "            dim=self.dim,\n",
    "            render_decimals=self.__render_decimals,\n",
    "        )\n",
    "\n",
    "    def __imul__(self, __other: 'Matrix[Numeric]', /) -> Self:\n",
    "        if self.dim != __other.dim:\n",
    "            raise ValueError(\n",
    "                f'Hadamard requires equal dims, got {self.dim} and {__other.dim}'\n",
    "            )\n",
    "        self.__values = cast(\n",
    "            tuple[Numeric, ...],\n",
    "            tuple(\n",
    "                self[i, j] * __other[i, j] for i, j\n",
    "                in product(range(self.dim.m), range(self.dim.n))\n",
    "            ),\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def __matmul__(self, __other: 'Matrix[Numeric]', /) -> 'Matrix[Numeric]':\n",
    "        if self.dim.n != __other.dim.m:\n",
    "            raise ValueError(f'Cannot multiply {self.dim} and {__other.dim} matrices')\n",
    "        return Matrix(\n",
    "            tuple(\n",
    "                sum(self[i, k] * __other[k, j] for k in range(self.dim.n))\n",
    "                for i, j in product(range(self.dim.m), range(__other.dim.n))\n",
    "            ),\n",
    "            dim=MatrixDim(m=self.dim.m, n=__other.dim.n),\n",
    "            transposed=False,\n",
    "            render_decimals=max(self.__render_decimals, __other.__render_decimals),\n",
    "        )\n",
    "\n",
    "    def __pow__(self, __power: int, /) -> 'Matrix[Numeric]':\n",
    "        return self.apply(lambda x: x ** __power)\n",
    "\n",
    "    def __eq__(self, __other: object, /) -> bool:\n",
    "        return isinstance(__other, Matrix) and self.dim == __other.dim and all(\n",
    "            self[i, j] == __other[i, j] for i, j\n",
    "            in product(range(self.dim.m), range(self.dim.n))\n",
    "        )\n",
    "\n",
    "    def __ne__(self, __other: object, /) -> bool:\n",
    "        return not self == __other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix[Numeric: (bool, int, float)](\n",
    "    __values: Sequence[Sequence[Numeric]], /, *, render_decimals: int = 0\n",
    ") -> Matrix[Numeric]:\n",
    "    dim: MatrixDim = MatrixDim(\n",
    "        m=len(__values), n=len(__values[0]) if len(__values) > 0 else 0\n",
    "    )\n",
    "    if not all(len(__values[i]) == dim.n for i in range(len(__values))):\n",
    "        raise ValueError('Matrix rows have different lengths')\n",
    "    return Matrix(tuple(chain(*__values)), dim, render_decimals=render_decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector[Numeric: (bool, int, float)](\n",
    "    __values: Sequence[Numeric], /, *, render_decimals: int = 0\n",
    ") -> Matrix[Numeric]:\n",
    "    return matrix([__values], render_decimals=render_decimals).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros(dim: MatrixDim, *, render_decimals: int = 0) -> Matrix[float]:\n",
    "    return Matrix((0.0,) * dim.size, dim=dim, render_decimals=render_decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_matrix[Numeric: (bool, int, float)](matrix: Matrix[Numeric]) -> str:\n",
    "    return f'{matrix.dim.m}*{matrix.dim.n}:{(\n",
    "        ','.join(\n",
    "            str(matrix[i, j]) for i, j in product(\n",
    "                range(matrix.dim.m), range(matrix.dim.n)\n",
    "            )\n",
    "        )\n",
    "    )}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_matrix[Numeric: (bool, int, float)](\n",
    "    string: str, dtype: type[Numeric] = float, render_decimals: int = 0\n",
    ") -> Matrix[Numeric]:\n",
    "    dim_string, values_string = string.split(sep=':', maxsplit=1)\n",
    "    dim: MatrixDim = MatrixDim(*map(int, dim_string.split(sep='*', maxsplit=1)))\n",
    "    return Matrix(\n",
    "        tuple(map(dtype, values_string.split(sep=','))),\n",
    "        dim=dim,\n",
    "        render_decimals=render_decimals,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(slots=True)\n",
    "class Function[**Ts, T]:\n",
    "    __func: Callable[Ts, T]\n",
    "    __ddx_func: Callable[Ts, T]\n",
    "\n",
    "    def __init__(\n",
    "        self, __func: Callable[Ts, T], __ddx_func: Callable[Ts, T]\n",
    "    ) -> None:\n",
    "        self.__func = __func\n",
    "        self.__ddx_func = __ddx_func\n",
    "\n",
    "    def __call__(self, x: T) -> T:\n",
    "        return self.__func(x)\n",
    "\n",
    "    @property\n",
    "    def ddx(self) -> Callable[Ts, T]:\n",
    "        return self.__ddx_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type ActivationFunction = Function[[float], float]\n",
    "type LossFunction = Function[[Matrix[float], Matrix[float]], Matrix[float]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: float) -> float:\n",
    "    return 1 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    NONE: ActivationFunction = Function(lambda x: x, lambda _: 1)\n",
    "    RELU: ActivationFunction = Function(lambda x: x * (x > 0), lambda x: x > 0)\n",
    "    SIGMOID: ActivationFunction = Function(\n",
    "        sigmoid, lambda x: sigmoid(x) * (1 - sigmoid(x))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(v: Matrix[float]) -> Matrix[float]:\n",
    "    exponents: list[float] = [exp(x - max(v.as_vector)) for x in v.as_vector]\n",
    "    return vector([e / sum(exponents) for e in exponents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    MSE: LossFunction = Function(\n",
    "        lambda x, y: (y - x) ** 2, lambda x, y: (x - y).apply(lambda v: 2 * v)\n",
    "    )\n",
    "    SOFTMAX_CROSSENTROPY: LossFunction = Function(\n",
    "        lambda z, y: (softmax(z) * y.apply(lambda t: -1.0 if t > 0 else 0.0)),\n",
    "        lambda z, y: softmax(z) - y,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(slots=True)\n",
    "class LinearLayer:\n",
    "    __w: Matrix[float]\n",
    "    __b: Matrix[float]\n",
    "    __activation: ActivationFunction\n",
    "    __last_input: Matrix[float] | None\n",
    "    __last_z: Matrix[float] | None\n",
    "    __grad_w: Matrix[float]\n",
    "    __grad_b: Matrix[float]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: MatrixDim,\n",
    "        activation: ActivationFunction,\n",
    "        render_decimals: int,\n",
    "    ) -> None:\n",
    "        limit: float = sqrt(6.0 / (dim.m + dim.n))\n",
    "        self.__w = Matrix(\n",
    "            [(2 * random() - 1) * limit for _ in range(dim.size)],\n",
    "            dim=dim,\n",
    "            render_decimals=2,\n",
    "        )\n",
    "        self.__b = vector(\n",
    "            [0.0 for _ in range(dim.m)],\n",
    "            render_decimals=render_decimals,\n",
    "        )\n",
    "        self.__activation = activation\n",
    "        self.__last_input = None\n",
    "        self.__last_z = None\n",
    "        self.__zero_gradients()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.__b)\n",
    "\n",
    "    @property\n",
    "    def weights(self) -> Matrix[float]:\n",
    "        return self.__w\n",
    "\n",
    "    @weights.setter\n",
    "    def weights(self, w: Matrix[float], /) -> None:\n",
    "        assert self.__w.dim == w.dim\n",
    "        self.__w = w\n",
    "\n",
    "    @property\n",
    "    def biases(self) -> Matrix[float]:\n",
    "        return self.__b\n",
    "\n",
    "    @biases.setter\n",
    "    def biases(self, b: Matrix[float], /) -> None:\n",
    "        assert self.__b.dim == b.dim\n",
    "        self.__b = b\n",
    "\n",
    "    def __zero_gradients(self) -> None:\n",
    "        self.__grad_w = zeros(self.__w.dim, render_decimals=0)\n",
    "        self.__grad_b = zeros(self.__b.dim, render_decimals=0)\n",
    "\n",
    "    def accumulate_grads(self, upstream: Matrix[float]) -> Matrix[float]:\n",
    "        if self.__last_input is None or self.__last_z is None:\n",
    "            raise RuntimeError('feed_forward must be called before accumulate_grads')\n",
    "        delta: Matrix[float] = upstream * self.__last_z.apply(self.__activation.ddx)\n",
    "        self.__grad_w += (delta @ self.__last_input.T)\n",
    "        self.__grad_b += delta\n",
    "        return self.__w.T @ delta\n",
    "\n",
    "    def feed_forward(self, input: Matrix[float]) -> Matrix[float]:\n",
    "        self.__last_input = input\n",
    "        self.__last_z = self.__w @ input + self.__b\n",
    "        return self.__last_z.apply(self.__activation)\n",
    "\n",
    "    def apply_grads(self, *, learning_rate: float, batch_size: int) -> None:\n",
    "        scale: float = learning_rate / float(batch_size)\n",
    "        self.__w -= self.__grad_w.apply(lambda g: scale * g)\n",
    "        self.__b -= self.__grad_b.apply(lambda g: scale * g)\n",
    "        self.__zero_gradients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True, slots=True)\n",
    "class LayerDescriptor:\n",
    "    n: int\n",
    "    activation: ActivationFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(\n",
    "    n: int, activation: ActivationFunction = Activation.NONE\n",
    ") -> LayerDescriptor:\n",
    "    return LayerDescriptor(n=n, activation=activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches[T](\n",
    "    iterable: Iterable[T], *, size: int, shuffled: bool = True\n",
    ") -> Iterable[list[T]]:\n",
    "    iterator: Iterator[T] = iter(iterable)\n",
    "    while batch := list(islice(iterator, size)):\n",
    "        if shuffled:\n",
    "            shuffle(batch)\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(slots=True)\n",
    "class Model[Answer]:\n",
    "    __input_size: int\n",
    "    __layers: list[LinearLayer]\n",
    "    __loss: LossFunction\n",
    "    __transform: Callable[[Matrix[float]], Answer]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        layers: list[LayerDescriptor],\n",
    "        loss: LossFunction,\n",
    "        transform: Callable[[Matrix[float]], Answer],\n",
    "        *,\n",
    "        render_decimals: int = 2,\n",
    "    ) -> None:\n",
    "        self.__input_size = input_size\n",
    "        self.__layers = [\n",
    "            LinearLayer(\n",
    "                dim=MatrixDim(d.n, d_prev.n),\n",
    "                activation=d.activation,\n",
    "                render_decimals=render_decimals,\n",
    "            )\n",
    "            for d_prev, d in zip(\n",
    "                chain([LayerDescriptor(input_size, Activation.NONE)], layers), layers\n",
    "            )\n",
    "        ]\n",
    "        self.__loss = loss\n",
    "        self.__transform = transform\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.summary\n",
    "\n",
    "    @property\n",
    "    def summary(self) -> str:\n",
    "        return f'Model: {self.__input_size} -> {(\n",
    "            ' -> '.join(f'L({len(layer)})' for layer in self.__layers)\n",
    "        )} -> {self.__transform.__name__}'\n",
    "\n",
    "    def __feed_forward(self, input: Matrix[float]) -> Matrix[float]:\n",
    "        result: Matrix[float] = input\n",
    "        for layer in self.__layers:\n",
    "            result = layer.feed_forward(result)\n",
    "        return result\n",
    "\n",
    "    def __update_weights(\n",
    "        self,\n",
    "        batch: list[tuple[Matrix[float], Matrix[float]]],\n",
    "        *,\n",
    "        learning_rate: float = 0.01,\n",
    "    ) -> None:\n",
    "        if len(batch) == 0:\n",
    "            return\n",
    "        for x, y in batch:\n",
    "            prediction: Matrix[float] = self.__feed_forward(x)\n",
    "            upstream: Matrix[float] = self.__loss.ddx(prediction, y)\n",
    "            for layer in reversed(self.__layers):\n",
    "                upstream = layer.accumulate_grads(upstream)\n",
    "        for layer in self.__layers:\n",
    "            layer.apply_grads(learning_rate=learning_rate, batch_size=len(batch))\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        xs: list[Matrix[float]],\n",
    "        ys: list[Matrix[float]],\n",
    "        *,\n",
    "        batch_size: int = 16,\n",
    "        epochs: int = 10,\n",
    "        learning_rate: float = 0.01,\n",
    "    ) -> None:\n",
    "        batch_count: int = (len(xs) + 1) // batch_size\n",
    "        print('+-------+' + '-' * (batch_count + 2))\n",
    "        print('| Epoch |' + f' {'Batches':^{(batch_count + 1)}} ')\n",
    "        print('+-------+' + '-' * (batch_count + 2), end=str())\n",
    "        for epoch in range(epochs):\n",
    "            print(f'\\n| {(f'{epoch + 1}/{epochs}'):^5} |', end=' ')\n",
    "            for batch in batches(zip(xs, ys, strict=True), size=batch_size):\n",
    "                print(end='#')\n",
    "                self.__update_weights(batch, learning_rate=learning_rate)\n",
    "\n",
    "    def evaluate(self, xs: Iterable[Matrix[float]], answers: Iterable[int]) -> float:\n",
    "        return sum(\n",
    "            self.predict(x) == answer\n",
    "            for x, answer in zip(xs, answers, strict=True)\n",
    "        ) / len(xs)\n",
    "\n",
    "    def predict(self, input: Matrix[float]) -> Answer:\n",
    "        return self.__transform(self.__feed_forward(input))\n",
    "\n",
    "    def save(self, folder: str, name: str | None = None) -> None:\n",
    "        default_name: str = self.summary.replace(\n",
    "            ' -> ', '_'\n",
    "        ).replace('(', str()).replace(')', str())\n",
    "        with Path(f'{folder}/{name or default_name}').open('w') as model_file:\n",
    "            for layer in self.__layers:\n",
    "                model_file.write(f'{serialize_matrix(layer.weights)}\\n')\n",
    "                model_file.write(f'{serialize_matrix(layer.biases)}\\n')\n",
    "\n",
    "    def load(self, folder: str, name: str) -> None:\n",
    "        with Path(f'{folder}/{name}').open('r') as model_file:\n",
    "            lines: list[str] = list(\n",
    "                filter(lambda line: line != str(), model_file.readlines())\n",
    "            )\n",
    "            for i, (w, b) in enumerate(zip(lines[::2], lines[1::2])):\n",
    "                self.__layers[i].weights = deserialize_matrix(w, dtype=float)\n",
    "                self.__layers[i].biases = deserialize_matrix(b, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_idx_images(path: str) -> list[Matrix[float]]:\n",
    "    with Path(path).open('rb') as images_file:\n",
    "        magic, num, rows, cols = cast(\n",
    "            tuple[int, int, int, int],\n",
    "            unpack('>IIII', images_file.read(16)),\n",
    "        )\n",
    "        if magic != 2051:\n",
    "            raise ValueError(f'Not an IDX image file (magic {magic})')\n",
    "        size: int = rows * cols\n",
    "        data: bytes = images_file.read()\n",
    "        if len(data) != num * size:\n",
    "            raise ValueError('Unexpected file length for image data')\n",
    "\n",
    "        images: list[Matrix[float]] = []\n",
    "        mv: memoryview[int] = memoryview(data)\n",
    "        for i in range(num):\n",
    "            start: int = i * size\n",
    "            vals: tuple[float, ...] = tuple(\n",
    "                v / 255.0 for v in mv[start:(start + size)].tolist()\n",
    "            )\n",
    "            images.append(Matrix(vals, dim=MatrixDim(size, 1), render_decimals=2))\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_idx_labels(path: str | Path) -> list[int]:\n",
    "    with Path(path).open('rb') as labels_file:\n",
    "        magic, num = cast(tuple[int, int], unpack('>II', labels_file.read(8)))\n",
    "        if magic != 2049:\n",
    "            raise ValueError(f'Not an IDX label file (magic {magic})')\n",
    "        data = labels_file.read()\n",
    "        if len(data) != num:\n",
    "            raise ValueError('Unexpected file length for label data')\n",
    "        mv: memoryview[int] = memoryview(data)\n",
    "        return mv.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "    path: str, prepare_image: Callable[[float], float] | None = None\n",
    ") -> tuple[list[Matrix[float]], list[int], list[Matrix[float]], list[int]]:\n",
    "    root: Path = Path(path)\n",
    "    train_images: list[Matrix[float]] = [\n",
    "        image.apply(prepare_image) if prepare_image is not None else image\n",
    "        for image in read_idx_images(\n",
    "            root / 'train-images-idx3-ubyte' / 'train-images-idx3-ubyte'\n",
    "        )\n",
    "    ]\n",
    "    train_labels: list[int] = read_idx_labels(\n",
    "        root / 'train-labels-idx1-ubyte' / 'train-labels-idx1-ubyte'\n",
    "    )\n",
    "    test_images: list[Matrix[float]] = [\n",
    "        image.apply(prepare_image) if prepare_image is not None else image\n",
    "        for image in read_idx_images(\n",
    "            root / 't10k-images-idx3-ubyte' / 't10k-images-idx3-ubyte'\n",
    "        )\n",
    "    ]\n",
    "    test_labels: list[int] = read_idx_labels(\n",
    "        root / 't10k-labels-idx1-ubyte' / 't10k-labels-idx1-ubyte'\n",
    "    )\n",
    "    return (train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(label: int, classes: int) -> Matrix[float]:\n",
    "    vec: list[float] = [0.0] * classes\n",
    "    vec[label] = 1\n",
    "    return vector(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(matrix: Matrix[float]) -> int:\n",
    "    return max(enumerate(matrix.as_vector), key=lambda element: element[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: Model[float] = Model(\n",
    "    input_size=784,\n",
    "    layers=[\n",
    "        layer(n=16, activation=Activation.SIGMOID),\n",
    "        layer(n=16, activation=Activation.SIGMOID),\n",
    "        layer(n=10),\n",
    "    ],\n",
    "    loss=Loss.SOFTMAX_CROSSENTROPY,\n",
    "    transform=argmax,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_dataset(path='mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    xs=x_train[:1000],\n",
    "    ys=[one_hot(y, classes=10) for y in y_train][:1000],\n",
    "    batch_size=32,\n",
    "    epochs=3,\n",
    "    learning_rate=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test[:1000], y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(folder='models', name='test.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m: Model[float] = Model(\n",
    "    input_size=784,\n",
    "    layers=[\n",
    "        layer(n=16, activation=Activation.SIGMOID),\n",
    "        layer(n=16, activation=Activation.SIGMOID),\n",
    "        layer(n=10),\n",
    "    ],\n",
    "    loss=Loss.SOFTMAX_CROSSENTROPY,\n",
    "    transform=argmax,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load(folder='models', name='test.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.evaluate(x_test[:1000], y_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from typing import Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CANVAS_SIZE: Final[int] = 280\n",
    "GRID_SIZE: Final[int] = 28\n",
    "SCALE: Final[int] = CANVAS_SIZE // GRID_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrawMNIST:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title('MNIST Live Prediction')\n",
    "\n",
    "        self.canvas = tk.Canvas(self.root, width=CANVAS_SIZE, height=CANVAS_SIZE, bg='black')\n",
    "        self.canvas.pack(side=tk.LEFT)\n",
    "\n",
    "        self.label_var = tk.StringVar()\n",
    "        self.label = tk.Label(self.root, textvariable=self.label_var, font=('Arial', 24))\n",
    "        self.label.pack(side=tk.RIGHT, padx=20)\n",
    "\n",
    "        self.image = Image.new('L', (CANVAS_SIZE, CANVAS_SIZE), 0)\n",
    "        self.draw = ImageDraw.Draw(self.image)\n",
    "\n",
    "        self.canvas.bind('<B1-Motion>', self.paint)\n",
    "        self.canvas.bind('<B3-Motion>', self.erase)\n",
    "\n",
    "        self.update_prediction()\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def paint(self, event):\n",
    "        x1, y1 = (event.x - 8), (event.y - 8)\n",
    "        x2, y2 = (event.x + 8), (event.y + 8)\n",
    "        self.canvas.create_oval(x1, y1, x2, y2, fill='white', outline='white')\n",
    "        self.draw.ellipse([x1, y1, x2, y2], fill=255)\n",
    "\n",
    "    def erase(self, event):\n",
    "        x1, y1 = (event.x - 8), (event.y - 8)\n",
    "        x2, y2 = (event.x + 8), (event.y + 8)\n",
    "        self.canvas.create_oval(x1, y1, x2, y2, fill='black', outline='black')\n",
    "        self.draw.ellipse([x1, y1, x2, y2], fill=0)\n",
    "\n",
    "    def get_matrix(self) -> Matrix[float]:\n",
    "        img_small = self.image.resize((GRID_SIZE, GRID_SIZE), Image.Resampling.LANCZOS)\n",
    "        arr = np.array(img_small).astype(np.float32) / 255.0\n",
    "        flat = arr.flatten().tolist()\n",
    "        return Matrix(tuple(flat), dim=MatrixDim(GRID_SIZE * GRID_SIZE, 1))\n",
    "\n",
    "    def update_prediction(self):\n",
    "        x = self.get_matrix()\n",
    "        pred = self.model.predict(x)\n",
    "        self.label_var.set(f'Prediction: {pred}')\n",
    "        self.root.after(500, self.update_prediction)  # update every 0.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawMNIST(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
